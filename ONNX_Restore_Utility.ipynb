{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step into correct dir",
   "id": "7e1b61ddec8234f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:39:34.455582Z",
     "start_time": "2025-06-17T14:39:34.451407Z"
    }
   },
   "cell_type": "code",
   "source": "%cd jku.wad",
   "id": "b0f8dffbe517c1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin\\Documents\\GitHub\\DRL_DOOM\\jku.wad\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Imports",
   "id": "8fa298324eab363d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:39:39.582070Z",
     "start_time": "2025-06-17T14:39:35.791340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Dict, Sequence, Tuple\n",
    "import os\n",
    "import torch\n",
    "from collections import deque, OrderedDict\n",
    "import collections\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "\n",
    "from gym import Env\n",
    "from torch import nn\n",
    "from einops import rearrange\n",
    "\n",
    "from doom_arena import VizdoomMPEnv\n",
    "from doom_arena.reward import VizDoomReward\n",
    "from doom_arena.render import render_episode\n",
    "from IPython.display import HTML\n",
    "from vizdoom import ScreenFormat\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ],
   "id": "1c517b170128a24c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:39:43.191550Z",
     "start_time": "2025-06-17T14:39:43.186563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LecturerReward(VizDoomReward):\n",
    "    def __init__(self, num_players: int):\n",
    "        super().__init__(num_players)\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        vizdoom_reward: float,\n",
    "        game_var: Dict[str, float],\n",
    "        game_var_old: Dict[str, float],\n",
    "        player_id: int,\n",
    "    ) -> Tuple[float, float, float]:\n",
    "        \"\"\"\n",
    "        Custom reward function used by both training and evaluation.\n",
    "        *  +100  for every new frag\n",
    "        *  +2    for every hit landed\n",
    "        *  -0.1  for every hit taken\n",
    "        \"\"\"\n",
    "        self._step += 1\n",
    "        _ = vizdoom_reward, player_id  # unused\n",
    "\n",
    "        rwd_hit        =  2.0  * (game_var[\"HITCOUNT\"]   - game_var_old[\"HITCOUNT\"])\n",
    "        rwd_hit_taken  = -0.1  * (game_var[\"HITS_TAKEN\"] - game_var_old[\"HITS_TAKEN\"])\n",
    "        rwd_frag       = 100.0 * (game_var[\"FRAGCOUNT\"]  - game_var_old[\"FRAGCOUNT\"])\n",
    "\n",
    "        return rwd_hit, rwd_hit_taken, rwd_frag"
   ],
   "id": "32ba5ff4a03120b6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Environment Config",
   "id": "67c92a23adec0702"
  },
  {
   "metadata": {
    "id": "nmNDlnmfzP62",
    "ExecuteTime": {
     "end_time": "2025-06-17T14:39:43.680472Z",
     "start_time": "2025-06-17T14:39:43.677144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "USE_GRAYSCALE = False # ← flip to False for RGB\n",
    "\n",
    "PLAYER_CONFIG = {\n",
    "    \"algo_type\": \"QVALUE\",\n",
    "    \"n_stack_frames\": 1,\n",
    "    \"extra_state\": [\"depth\"],\n",
    "    \"hud\": \"none\",\n",
    "    \"crosshair\": True,\n",
    "    \"screen_format\": 8 if USE_GRAYSCALE else 0\n",
    "}"
   ],
   "id": "dbab296e230293c6",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "id": "A3vdawvQzP62",
    "ExecuteTime": {
     "end_time": "2025-06-17T14:39:43.882850Z",
     "start_time": "2025-06-17T14:39:43.879185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO: environment training paramters\n",
    "N_STACK_FRAMES = 1\n",
    "NUM_BOTS = 4\n",
    "EPISODE_TIMEOUT = 1000\n",
    "\n",
    "#SCREEN_WIDTH = 120\n",
    "#SCREEN_HEIGHT = 90\n",
    "SCREEN_CHANNELS = 3 if not USE_GRAYSCALE else 1\n",
    "EXTRA_STATE = [\"depth\"]\n",
    "HUD = \"none\"\n",
    "CROSSHAIR = True\n",
    "ACTION_SPACE = 7\n",
    "#OBSERVATION_SPACE = (SCREEN_CHANNELS * N_STACK_FRAMES, SCREEN_HEIGHT, SCREEN_WIDTH)\n",
    "\n",
    "# TODO: model hyperparams\n",
    "GAMMA = 0.997\n",
    "# EPISODES = 100\n",
    "EPISODES = 2000\n",
    "BATCH_SIZE = 64\n",
    "REPLAY_BUFFER_SIZE = 30000\n",
    "LEARNING_RATE = 3e-4\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_END = 0.1\n",
    "EPSILON_DECAY = 0.999\n",
    "N_EPOCHS = 1"
   ],
   "id": "13a0e6d73f16b8f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFNHtfouMvKB",
    "outputId": "fbf3c410-fb81-466f-8808-bfdb8821c88a",
    "ExecuteTime": {
     "end_time": "2025-06-17T14:39:44.260414Z",
     "start_time": "2025-06-17T14:39:44.188613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ],
   "id": "174b72a2f68432e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OzTS4m2VzP63",
    "outputId": "a6d55f1b-36cf-4a0c-8a93-ce36d710dc79",
    "ExecuteTime": {
     "end_time": "2025-06-17T14:39:44.677458Z",
     "start_time": "2025-06-17T14:39:44.671512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DTYPE = torch.float32\n",
    "\n",
    "env = VizdoomMPEnv(\n",
    "        num_players=1,\n",
    "        num_bots=4,\n",
    "        bot_skill=0,\n",
    "        doom_map=\"ROOM\",\n",
    "        episode_timeout=2000,\n",
    "        screen_format=PLAYER_CONFIG[\"screen_format\"],\n",
    "        n_stack_frames=PLAYER_CONFIG[\"n_stack_frames\"],\n",
    "        extra_state=EXTRA_STATE,\n",
    "        hud=PLAYER_CONFIG[\"hud\"],\n",
    "        crosshair=PLAYER_CONFIG[\"crosshair\"],\n",
    "        seed=PLAYER_CONFIG,\n",
    "    )"
   ],
   "id": "713613eba419ac43",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Host 52287\n",
      "Player 52287\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Trying to restore the good model and save",
   "id": "14d81fca72d8b8ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Utility to load onnx and save with new config",
   "id": "d65793f3c0293fa8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T18:53:03.406043Z",
     "start_time": "2025-06-16T18:53:03.396564Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 73,
   "source": [
    "#model_time = curr_time\n",
    "import onnx\n",
    "import onnx2pytorch as o2t\n",
    "model_time = \"2025_06_14 11_07_42\"\n",
    "#model_path = f\"model_{model_time}.onnx\"\n",
    "model_path = \"migrated_model_for_eval_2025_06_14 11_07_40.onnx\"\n",
    "#model_path = \"restored_model_2025_06_14 11_07_40.onnx\"\n",
    "\n",
    "loaded_model = onnx.load(model_path)\n",
    "\n",
    "loaded_torch_model = o2t.ConvertModel(loaded_model)"
   ],
   "id": "35c799617e127ac2"
  },
  {
   "metadata": {
    "id": "pP6UxV5NzP64",
    "ExecuteTime": {
     "end_time": "2025-06-17T14:40:01.487745Z",
     "start_time": "2025-06-17T14:40:01.481972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ================================================================\n",
    "# DQN — design your network here\n",
    "# ================================================================\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    \"\"\"\n",
    "    Deep-Q Network template.\n",
    "\n",
    "    Expected behaviour\n",
    "    ------------------\n",
    "    forward(frame)      # frame: (B, C, H, W)  →  Q-values: (B, num_actions)\n",
    "\n",
    "    What to add / change\n",
    "    --------------------\n",
    "    • Replace the two `NotImplementedError` lines.\n",
    "    • Build an encoder (Conv2d / Conv3d) + a head (MLP or duelling).\n",
    "    • Feel free to use residual blocks from `agents/utils.py` or any design you like.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim: int, action_space: int, hidden: int = 128):\n",
    "        super().__init__()\n",
    "\n",
    "        # -------- TODO: define your layers ------------------------\n",
    "        # Example (very small) baseline — delete or improve:\n",
    "        #\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(input_dim, 32, 8, stride=4), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 4, stride=2),       nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, stride=1),       nn.ReLU(),\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 12 * 12, hidden), nn.ReLU(),\n",
    "            nn.Linear(hidden, action_space),\n",
    "        )\n",
    "        # -----------------------------------------------------------\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, frame: torch.Tensor) -> torch.Tensor:\n",
    "        # -------- TODO: implement forward -------------------------\n",
    "        x = self.encoder(frame)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "        # -----------------------------------------------------------\n"
   ],
   "id": "237708628cc4e26f",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "id": "n7dWjwTdzP65",
    "ExecuteTime": {
     "end_time": "2025-06-17T14:40:49.693350Z",
     "start_time": "2025-06-17T14:40:49.538872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ================================================================\n",
    "# Initialise your networks and training utilities\n",
    "# ================================================================\n",
    "load = False\n",
    "\n",
    "# main Q-network\n",
    "in_channels = env.observation_space.shape[0]   # 1 if grayscale, else 3/4\n",
    "model = DQN(\n",
    "    input_dim    = in_channels,\n",
    "    action_space = env.action_space.n,\n",
    "    hidden       = 64,   # change or ignore\n",
    ").to(device, dtype=DTYPE)\n",
    "if load:\n",
    "    model.load_state_dict(torch.load(\"save_curr_model_2025_06_13 23_34_15.pt\"))\n",
    "# TODO ------------------------------------------------------------\n",
    "# 1. Create a target network (hard-copy or EMA)\n",
    "# 2. Choose an optimiser + learning-rate schedule\n",
    "# 3. Instantiate a replay buffer and set the initial epsilon value\n",
    "#\n",
    "# Hints:\n",
    "model_tgt  = deepcopy(model).to(device)\n",
    "# previosly trained with model_tgt parameters\n",
    "optimizer  = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler  = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=GAMMA)\n",
    "replay_buffer = collections.deque(maxlen=REPLAY_BUFFER_SIZE)\n",
    "#replay_buffer = PrioritizedReplayBuffer(REPLAY_BUFFER_SIZE)\n",
    "# ---------------------------------------------------------------\n"
   ],
   "id": "dcb433a5817b0230",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "id": "YNkgBbUSzP66",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "22cd5d3a-302d-48e1-9676-3044a3aca6a4",
    "ExecuteTime": {
     "end_time": "2025-06-17T13:55:35.704404Z",
     "start_time": "2025-06-17T13:55:35.699922Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 108,
   "source": [
    "# ---------------------------------------------------------------\n",
    "# 🧭 model save\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "import onnx\n",
    "import json\n",
    "\n",
    "\n",
    "def onnx_dump(env, model, config, filename: str):\n",
    "    # dummy state\n",
    "    init_state = env.reset()[0].unsqueeze(0)\n",
    "\n",
    "\n",
    "    # Export to ONNX\n",
    "    torch.onnx.export(\n",
    "        model.cpu(),\n",
    "        args=init_state,\n",
    "        f=filename,\n",
    "        export_params=True,\n",
    "        opset_version=11,\n",
    "        do_constant_folding=True,\n",
    "        input_names=[\"input\"],\n",
    "        output_names=[\"output\"],\n",
    "        dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}},\n",
    "    )\n",
    "    onnx_model = onnx.load(filename)\n",
    "\n",
    "    meta = onnx_model.metadata_props.add()\n",
    "    meta.key = \"config\"\n",
    "    meta.value = json.dumps(config)\n",
    "\n",
    "    onnx.save(onnx_model, filename)"
   ],
   "id": "c250683f274abc28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:40:50.543861Z",
     "start_time": "2025-06-17T14:40:50.519441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_time = \"2025_06_14 11_07_40\"\n",
    "restored_model = DQN(\n",
    "    input_dim    = in_channels,\n",
    "    action_space = env.action_space.n,\n",
    "    hidden       = 64,   # change or ignore\n",
    ").to(device, dtype=DTYPE)\n",
    "\n",
    "restored_model.load_state_dict(torch.load(f\"save_curr_model_{model_time}.pt\"))\n"
   ],
   "id": "487c1029a49b0bf9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T18:50:43.741887Z",
     "start_time": "2025-06-16T18:50:42.911972Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 68,
   "source": "onnx_dump(env, restored_model, PLAYER_CONFIG, filename=f\"restored_model_{model_time}.onnx\")",
   "id": "601a3444f82e01f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T18:02:07.042342Z",
     "start_time": "2025-06-16T18:02:07.035362Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 39,
   "source": [
    "class DQN_NEW(nn.Module):\n",
    "    \"\"\"\n",
    "    Deep-Q Network with fixes for ONNX compatibility\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim: int, action_space: int, hidden: int = 128):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_dim, 32, 8, stride=4)\n",
    "        self.ac1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(32, 64, 4, stride=2)\n",
    "        self.ac2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, stride=1)\n",
    "        self.ac3 = nn.ReLU()\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 12 * 12, hidden)\n",
    "        self.ac4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden, action_space)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, frame: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.ac1(self.conv1(frame))\n",
    "        x = self.ac2(self.conv2(x))\n",
    "        x = self.ac3(self.conv3(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.ac4(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "id": "344e4b3d702ddfb2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Convert Model to model with no bias",
   "id": "ee8af7417ffbbd78"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T18:51:28.940292Z",
     "start_time": "2025-06-16T18:51:28.929171Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 70,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import onnx\n",
    "import json\n",
    "# Make sure your utility functions like onnx_dump and get_timestamp are available\n",
    "# and the environment 'env' is initialized.\n",
    "\n",
    "model_time = \"2025_06_14 11_07_40\"\n",
    "\n",
    "# --- PATHS TO YOUR FILES ---\n",
    "OLD_STATE_DICT_PATH = f\"save_curr_model_{model_time}.pt\" # <--- YOUR .pt FILE\n",
    "NEW_ONNX_PATH = f\"migrated_model_for_eval_{model_time}.onnx\"          # <--- Desired output ONNX file name\n",
    "\n",
    "# 1. Instantiate the NEW, corrected model structure\n",
    "model = DQN_NEW(\n",
    "    input_dim    = in_channels,\n",
    "    action_space = env.action_space.n,\n",
    "    hidden=64\n",
    ")\n",
    "\n",
    "new_state_dict = model.state_dict()"
   ],
   "id": "e72ea46c3ead98de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T18:51:52.963201Z",
     "start_time": "2025-06-16T18:51:52.210784Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded weights into the new model structure!\n",
      "Exporting corrected model to migrated_model_for_eval_2025_06_14 11_07_40.onnx...\n",
      "Export complete. You can now use this ONNX file for evaluation.\n"
     ]
    }
   ],
   "execution_count": 71,
   "source": [
    "\n",
    "# 2. Load the weights from your old trained model\n",
    "old_state_dict = torch.load(OLD_STATE_DICT_PATH)\n",
    "\n",
    "# 3. Define the mapping from old Sequential names to new named layers\n",
    "#    Old model names were like 'encoder.0', 'head.1', etc.\n",
    "#    New model names are like 'conv1', 'fc1', etc.\n",
    "key_mapping = {\n",
    "    'encoder.0.weight': 'conv1.weight',\n",
    "    'encoder.0.bias':   'conv1.bias',\n",
    "    'encoder.2.weight': 'conv2.weight',  # Skip 'encoder.1' (ReLU)\n",
    "    'encoder.2.bias':   'conv2.bias',\n",
    "    'encoder.4.weight': 'conv3.weight',  # Skip 'encoder.3' (ReLU)\n",
    "    'encoder.4.bias':   'conv3.bias',\n",
    "    'head.1.weight':    'fc1.weight',    # Skip 'head.0' (Flatten)\n",
    "    'head.1.bias':      'fc1.bias',\n",
    "    'head.3.weight':    'fc2.weight',    # Skip 'head.2' (ReLU)\n",
    "    'head.3.bias':      'fc2.bias',\n",
    "}\n",
    "\n",
    "# 4. Create a new state dictionary with the correct keys\n",
    "new_state_dict = OrderedDict()\n",
    "for old_key, value in old_state_dict.items():\n",
    "    if old_key in key_mapping:\n",
    "        new_key = key_mapping[old_key]\n",
    "        new_state_dict[new_key] = value\n",
    "    else:\n",
    "        # This part is a safety check. If there are unexpected keys, we'll know.\n",
    "        print(f\"Warning: Key '{old_key}' not found in mapping. Skipping.\")\n",
    "\n",
    "# 5. Load the newly constructed state_dict into the model\n",
    "try:\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    print(\"Successfully loaded weights into the new model structure!\")\n",
    "except RuntimeError as e:\n",
    "    print(\"Error loading state dict. This might be due to a mismatch in layer shapes.\")\n",
    "    print(\"This can happen if your old model was trained with the incorrect linear layer size (e.g., 64*12*12).\")\n",
    "    print(f\"Error details: {e}\")\n",
    "    # If you see this error, you likely cannot migrate the weights for the linear layers\n",
    "    # and will need to retrain.\n",
    "\n",
    "# 6. Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# 7. Export the newly loaded and corrected model to ONNX for the evaluation script\n",
    "#    Make sure the 'env' and 'PLAYER_CONFIG' variables are defined as in your training script.\n",
    "print(f\"Exporting corrected model to {NEW_ONNX_PATH}...\")\n",
    "onnx_dump(env, model, PLAYER_CONFIG, filename=NEW_ONNX_PATH)\n",
    "print(\"Export complete. You can now use this ONNX file for evaluation.\")"
   ],
   "id": "f9bb18781d5d5310"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T18:50:32.724497Z",
     "start_time": "2025-06-16T18:50:32.720828Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 66,
   "source": [
    "def onnx_dump(env, model, config, filename: str):\n",
    "    # dummy state\n",
    "    init_state = env.reset()[0].unsqueeze(0)\n",
    "\n",
    "\n",
    "    # Export to ONNX\n",
    "    torch.onnx.export(\n",
    "        model.cpu(),\n",
    "        args=init_state,\n",
    "        f=filename,\n",
    "        #export_params=True,\n",
    "        opset_version=20,\n",
    "        #do_constant_folding=True,\n",
    "        #input_names=[\"input\"],\n",
    "        #output_names=[\"output\"],\n",
    "        #dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}},\n",
    "    )\n",
    "    onnx_model = onnx.load(filename)\n",
    "\n",
    "    meta = onnx_model.metadata_props.add()\n",
    "    meta.key = \"config\"\n",
    "    meta.value = json.dumps(config)\n",
    "\n",
    "    onnx.save(onnx_model, filename)"
   ],
   "id": "9bab22754b189f33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T18:20:48.404854Z",
     "start_time": "2025-06-16T18:20:47.684703Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 53,
   "source": "init_state = env.reset()[0].unsqueeze(0)",
   "id": "ee4ab242e57fd010"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T18:48:31.218210Z",
     "start_time": "2025-06-16T18:39:50.726088Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Host 51863\n",
      "Player 51863\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[61]\u001B[39m\u001B[32m, line 100\u001B[39m\n\u001B[32m     98\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m seed \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     99\u001B[39m         seed = np.random.randint(\u001B[32m1e7\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m100\u001B[39m     scores.append(\u001B[43mrun_episode\u001B[49m\u001B[43m(\u001B[49m\u001B[43magent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m=\u001B[49m\u001B[43mseed\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m    102\u001B[39m \u001B[38;5;66;03m# Print result\u001B[39;00m\n\u001B[32m    103\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[61]\u001B[39m\u001B[32m, line 79\u001B[39m, in \u001B[36mrun_episode\u001B[39m\u001B[34m(agent, seed)\u001B[39m\n\u001B[32m     77\u001B[39m obs = obs[\u001B[32m0\u001B[39m]\n\u001B[32m     78\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m---> \u001B[39m\u001B[32m79\u001B[39m     action = \u001B[43magent\u001B[49m.select_action(obs)\n\u001B[32m     80\u001B[39m obs, rwd, done, _ = env.step(action)\n\u001B[32m     81\u001B[39m score += rwd[\u001B[32m0\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m_pydevd_bundle\\\\pydevd_cython_win32_312_64.pyx:1187\u001B[39m, in \u001B[36m_pydevd_bundle.pydevd_cython_win32_312_64.SafeCallWrapper.__call__\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m_pydevd_bundle\\\\pydevd_cython_win32_312_64.pyx:627\u001B[39m, in \u001B[36m_pydevd_bundle.pydevd_cython_win32_312_64.PyDBFrame.trace_dispatch\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m_pydevd_bundle\\\\pydevd_cython_win32_312_64.pyx:937\u001B[39m, in \u001B[36m_pydevd_bundle.pydevd_cython_win32_312_64.PyDBFrame.trace_dispatch\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m_pydevd_bundle\\\\pydevd_cython_win32_312_64.pyx:928\u001B[39m, in \u001B[36m_pydevd_bundle.pydevd_cython_win32_312_64.PyDBFrame.trace_dispatch\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m_pydevd_bundle\\\\pydevd_cython_win32_312_64.pyx:585\u001B[39m, in \u001B[36m_pydevd_bundle.pydevd_cython_win32_312_64.PyDBFrame.do_wait_suspend\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Program Files\\JetBrains\\PyCharm 2022.3.3\\plugins\\python-ce\\helpers\\pydev\\pydevd.py:1220\u001B[39m, in \u001B[36mPyDB.do_wait_suspend\u001B[39m\u001B[34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[39m\n\u001B[32m   1217\u001B[39m         from_this_thread.append(frame_id)\n\u001B[32m   1219\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._threads_suspended_single_notification.notify_thread_suspended(thread_id, stop_reason):\n\u001B[32m-> \u001B[39m\u001B[32m1220\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Program Files\\JetBrains\\PyCharm 2022.3.3\\plugins\\python-ce\\helpers\\pydev\\pydevd.py:1235\u001B[39m, in \u001B[36mPyDB._do_wait_suspend\u001B[39m\u001B[34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[39m\n\u001B[32m   1232\u001B[39m             \u001B[38;5;28mself\u001B[39m._call_mpl_hook()\n\u001B[32m   1234\u001B[39m         \u001B[38;5;28mself\u001B[39m.process_internal_commands()\n\u001B[32m-> \u001B[39m\u001B[32m1235\u001B[39m         \u001B[43mtime\u001B[49m\u001B[43m.\u001B[49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   1237\u001B[39m \u001B[38;5;28mself\u001B[39m.cancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[32m   1239\u001B[39m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 61,
   "source": [
    "import enum\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "\n",
    "\n",
    "################################ eval notebook start ###################################\n",
    "class ObsBuffer(enum.Enum):\n",
    "    LABELS = \"labels\"\n",
    "    DEPTH = \"depth\"\n",
    "    AUTOMAP = \"automap\"\n",
    "\n",
    "\n",
    "DTYPE = torch.float32\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Seed random number generators\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if os.path.exists(\"seed.rnd\"):\n",
    "    with open(\"seed.rnd\", \"r\") as f:\n",
    "        seed = int(f.readline().strip())\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "else:\n",
    "    seed = 1337\n",
    "\n",
    "\n",
    "def make_env(seed, config) -> VizdoomMPEnv:\n",
    "    extra_state = None\n",
    "    if config[\"extra_state\"] is not None:\n",
    "        extra_state = []\n",
    "        for c in config[\"extra_state\"]:\n",
    "            if c in {e.value for e in ObsBuffer}:\n",
    "                extra_state.append(ObsBuffer(c))\n",
    "\n",
    "    env = VizdoomMPEnv(\n",
    "        num_players=1,\n",
    "        num_bots=4,\n",
    "        bot_skill=0,\n",
    "        doom_map=\"ROOM\",\n",
    "        episode_timeout=2000,\n",
    "        screen_format=config[\"screen_format\"],\n",
    "        n_stack_frames=config[\"n_stack_frames\"],\n",
    "        extra_state=extra_state,\n",
    "        hud=config[\"hud\"],\n",
    "        crosshair=config[\"crosshair\"],\n",
    "        seed=seed,\n",
    "    )\n",
    "    return env\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, model, config, device):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "\n",
    "    def select_action(self, frames):\n",
    "        frames = frames.unsqueeze(0).to(DEVICE, dtype=DTYPE)\n",
    "        logits = self.model(frames)\n",
    "        if isinstance(logits, tuple):\n",
    "            logits, _ = logits\n",
    "        if \"algo_type\" not in self.config or self.config[\"algo_type\"] == \"POLICY\":\n",
    "            act = Categorical(logits=logits).sample()\n",
    "        else:\n",
    "            act = logits.argmax(-1)\n",
    "        return act.cpu().numpy()[0]\n",
    "\n",
    "\n",
    "def run_episode(agent: Agent, seed: int = 1337):\n",
    "    env = make_env(seed, config=agent.config)\n",
    "    obs = env.reset()\n",
    "    score = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        obs = obs[0]\n",
    "        with torch.no_grad():\n",
    "            action = agent.select_action(obs)\n",
    "        obs, rwd, done, _ = env.step(action)\n",
    "        score += rwd[0]\n",
    "    env.close()\n",
    "    return score\n",
    "\n",
    "\n",
    "# Run evaluation\n",
    "config = PLAYER_CONFIG\n",
    "#config[\"extra_state\"] = \"depth\"\n",
    "n_episodes = 10\n",
    "model = restored_model\n",
    "model.eval()\n",
    "model = model.to(DEVICE, dtype=DTYPE)\n",
    "agent = Agent(model, config, DEVICE)\n",
    "\n",
    "# Evaluate model\n",
    "scores = []\n",
    "for i in range(n_episodes):\n",
    "    if seed is not None:\n",
    "        seed = np.random.randint(1e7)\n",
    "    scores.append(run_episode(agent, seed=seed))\n",
    "\n",
    "# Print result\n",
    "print(\"\\n\\n\\n\")\n",
    "print(np.mean(scores))"
   ],
   "id": "d5dac70c7f36c11e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
