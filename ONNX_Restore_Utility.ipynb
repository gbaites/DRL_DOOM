{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import torch\n",
   "id": "1c517b170128a24c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Trying to restore the good model and save",
   "id": "14d81fca72d8b8ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Utility to load onnx and save with new config",
   "id": "d65793f3c0293fa8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T18:53:03.406043Z",
     "start_time": "2025-06-16T18:53:03.396564Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 73,
   "source": [
    "#model_time = curr_time\n",
    "import onnx\n",
    "import onnx2pytorch as o2t\n",
    "model_time = \"2025_06_14 11_07_42\"\n",
    "#model_path = f\"model_{model_time}.onnx\"\n",
    "model_path = \"migrated_model_for_eval_2025_06_14 11_07_40.onnx\"\n",
    "#model_path = \"restored_model_2025_06_14 11_07_40.onnx\"\n",
    "\n",
    "loaded_model = onnx.load(model_path)\n",
    "\n",
    "loaded_torch_model = o2t.ConvertModel(loaded_model)"
   ],
   "id": "35c799617e127ac2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T18:50:40.584444Z",
     "start_time": "2025-06-16T18:50:40.565763Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67,
   "source": [
    "model_time = \"2025_06_14 11_07_40\"\n",
    "restored_model = DQN(\n",
    "    input_dim    = in_channels,\n",
    "    action_space = env.action_space.n,\n",
    "    hidden       = 64,   # change or ignore\n",
    ").to(device, dtype=DTYPE)\n",
    "\n",
    "restored_model.load_state_dict(torch.load(f\"save_curr_model_{model_time}.pt\"))\n"
   ],
   "id": "487c1029a49b0bf9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T18:50:43.741887Z",
     "start_time": "2025-06-16T18:50:42.911972Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 68,
   "source": "onnx_dump(env, restored_model, PLAYER_CONFIG, filename=f\"restored_model_{model_time}.onnx\")",
   "id": "601a3444f82e01f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T18:02:07.042342Z",
     "start_time": "2025-06-16T18:02:07.035362Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 39,
   "source": [
    "class DQN_NEW(nn.Module):\n",
    "    \"\"\"\n",
    "    Deep-Q Network with fixes for ONNX compatibility\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim: int, action_space: int, hidden: int = 128):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_dim, 32, 8, stride=4)\n",
    "        self.ac1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(32, 64, 4, stride=2)\n",
    "        self.ac2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, stride=1)\n",
    "        self.ac3 = nn.ReLU()\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 12 * 12, hidden)\n",
    "        self.ac4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden, action_space)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, frame: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.ac1(self.conv1(frame))\n",
    "        x = self.ac2(self.conv2(x))\n",
    "        x = self.ac3(self.conv3(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.ac4(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "id": "344e4b3d702ddfb2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Convert Model to model with no bias",
   "id": "ee8af7417ffbbd78"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T18:51:28.940292Z",
     "start_time": "2025-06-16T18:51:28.929171Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 70,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import onnx\n",
    "import json\n",
    "# Make sure your utility functions like onnx_dump and get_timestamp are available\n",
    "# and the environment 'env' is initialized.\n",
    "\n",
    "model_time = \"2025_06_14 11_07_40\"\n",
    "\n",
    "# --- PATHS TO YOUR FILES ---\n",
    "OLD_STATE_DICT_PATH = f\"save_curr_model_{model_time}.pt\" # <--- YOUR .pt FILE\n",
    "NEW_ONNX_PATH = f\"migrated_model_for_eval_{model_time}.onnx\"          # <--- Desired output ONNX file name\n",
    "\n",
    "# 1. Instantiate the NEW, corrected model structure\n",
    "model = DQN_NEW(\n",
    "    input_dim    = in_channels,\n",
    "    action_space = env.action_space.n,\n",
    "    hidden=64\n",
    ")\n",
    "\n",
    "new_state_dict = model.state_dict()"
   ],
   "id": "e72ea46c3ead98de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T18:51:52.963201Z",
     "start_time": "2025-06-16T18:51:52.210784Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded weights into the new model structure!\n",
      "Exporting corrected model to migrated_model_for_eval_2025_06_14 11_07_40.onnx...\n",
      "Export complete. You can now use this ONNX file for evaluation.\n"
     ]
    }
   ],
   "execution_count": 71,
   "source": [
    "\n",
    "# 2. Load the weights from your old trained model\n",
    "old_state_dict = torch.load(OLD_STATE_DICT_PATH)\n",
    "\n",
    "# 3. Define the mapping from old Sequential names to new named layers\n",
    "#    Old model names were like 'encoder.0', 'head.1', etc.\n",
    "#    New model names are like 'conv1', 'fc1', etc.\n",
    "key_mapping = {\n",
    "    'encoder.0.weight': 'conv1.weight',\n",
    "    'encoder.0.bias':   'conv1.bias',\n",
    "    'encoder.2.weight': 'conv2.weight',  # Skip 'encoder.1' (ReLU)\n",
    "    'encoder.2.bias':   'conv2.bias',\n",
    "    'encoder.4.weight': 'conv3.weight',  # Skip 'encoder.3' (ReLU)\n",
    "    'encoder.4.bias':   'conv3.bias',\n",
    "    'head.1.weight':    'fc1.weight',    # Skip 'head.0' (Flatten)\n",
    "    'head.1.bias':      'fc1.bias',\n",
    "    'head.3.weight':    'fc2.weight',    # Skip 'head.2' (ReLU)\n",
    "    'head.3.bias':      'fc2.bias',\n",
    "}\n",
    "\n",
    "# 4. Create a new state dictionary with the correct keys\n",
    "new_state_dict = OrderedDict()\n",
    "for old_key, value in old_state_dict.items():\n",
    "    if old_key in key_mapping:\n",
    "        new_key = key_mapping[old_key]\n",
    "        new_state_dict[new_key] = value\n",
    "    else:\n",
    "        # This part is a safety check. If there are unexpected keys, we'll know.\n",
    "        print(f\"Warning: Key '{old_key}' not found in mapping. Skipping.\")\n",
    "\n",
    "# 5. Load the newly constructed state_dict into the model\n",
    "try:\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    print(\"Successfully loaded weights into the new model structure!\")\n",
    "except RuntimeError as e:\n",
    "    print(\"Error loading state dict. This might be due to a mismatch in layer shapes.\")\n",
    "    print(\"This can happen if your old model was trained with the incorrect linear layer size (e.g., 64*12*12).\")\n",
    "    print(f\"Error details: {e}\")\n",
    "    # If you see this error, you likely cannot migrate the weights for the linear layers\n",
    "    # and will need to retrain.\n",
    "\n",
    "# 6. Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# 7. Export the newly loaded and corrected model to ONNX for the evaluation script\n",
    "#    Make sure the 'env' and 'PLAYER_CONFIG' variables are defined as in your training script.\n",
    "print(f\"Exporting corrected model to {NEW_ONNX_PATH}...\")\n",
    "onnx_dump(env, model, PLAYER_CONFIG, filename=NEW_ONNX_PATH)\n",
    "print(\"Export complete. You can now use this ONNX file for evaluation.\")"
   ],
   "id": "f9bb18781d5d5310"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T18:50:32.724497Z",
     "start_time": "2025-06-16T18:50:32.720828Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 66,
   "source": [
    "def onnx_dump(env, model, config, filename: str):\n",
    "    # dummy state\n",
    "    init_state = env.reset()[0].unsqueeze(0)\n",
    "\n",
    "\n",
    "    # Export to ONNX\n",
    "    torch.onnx.export(\n",
    "        model.cpu(),\n",
    "        args=init_state,\n",
    "        f=filename,\n",
    "        #export_params=True,\n",
    "        opset_version=20,\n",
    "        #do_constant_folding=True,\n",
    "        #input_names=[\"input\"],\n",
    "        #output_names=[\"output\"],\n",
    "        #dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}},\n",
    "    )\n",
    "    onnx_model = onnx.load(filename)\n",
    "\n",
    "    meta = onnx_model.metadata_props.add()\n",
    "    meta.key = \"config\"\n",
    "    meta.value = json.dumps(config)\n",
    "\n",
    "    onnx.save(onnx_model, filename)"
   ],
   "id": "9bab22754b189f33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T18:20:48.404854Z",
     "start_time": "2025-06-16T18:20:47.684703Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 53,
   "source": "init_state = env.reset()[0].unsqueeze(0)",
   "id": "ee4ab242e57fd010"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T18:48:31.218210Z",
     "start_time": "2025-06-16T18:39:50.726088Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Host 51863\n",
      "Player 51863\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[61]\u001B[39m\u001B[32m, line 100\u001B[39m\n\u001B[32m     98\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m seed \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     99\u001B[39m         seed = np.random.randint(\u001B[32m1e7\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m100\u001B[39m     scores.append(\u001B[43mrun_episode\u001B[49m\u001B[43m(\u001B[49m\u001B[43magent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m=\u001B[49m\u001B[43mseed\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m    102\u001B[39m \u001B[38;5;66;03m# Print result\u001B[39;00m\n\u001B[32m    103\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[61]\u001B[39m\u001B[32m, line 79\u001B[39m, in \u001B[36mrun_episode\u001B[39m\u001B[34m(agent, seed)\u001B[39m\n\u001B[32m     77\u001B[39m obs = obs[\u001B[32m0\u001B[39m]\n\u001B[32m     78\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m---> \u001B[39m\u001B[32m79\u001B[39m     action = \u001B[43magent\u001B[49m.select_action(obs)\n\u001B[32m     80\u001B[39m obs, rwd, done, _ = env.step(action)\n\u001B[32m     81\u001B[39m score += rwd[\u001B[32m0\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m_pydevd_bundle\\\\pydevd_cython_win32_312_64.pyx:1187\u001B[39m, in \u001B[36m_pydevd_bundle.pydevd_cython_win32_312_64.SafeCallWrapper.__call__\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m_pydevd_bundle\\\\pydevd_cython_win32_312_64.pyx:627\u001B[39m, in \u001B[36m_pydevd_bundle.pydevd_cython_win32_312_64.PyDBFrame.trace_dispatch\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m_pydevd_bundle\\\\pydevd_cython_win32_312_64.pyx:937\u001B[39m, in \u001B[36m_pydevd_bundle.pydevd_cython_win32_312_64.PyDBFrame.trace_dispatch\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m_pydevd_bundle\\\\pydevd_cython_win32_312_64.pyx:928\u001B[39m, in \u001B[36m_pydevd_bundle.pydevd_cython_win32_312_64.PyDBFrame.trace_dispatch\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m_pydevd_bundle\\\\pydevd_cython_win32_312_64.pyx:585\u001B[39m, in \u001B[36m_pydevd_bundle.pydevd_cython_win32_312_64.PyDBFrame.do_wait_suspend\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Program Files\\JetBrains\\PyCharm 2022.3.3\\plugins\\python-ce\\helpers\\pydev\\pydevd.py:1220\u001B[39m, in \u001B[36mPyDB.do_wait_suspend\u001B[39m\u001B[34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[39m\n\u001B[32m   1217\u001B[39m         from_this_thread.append(frame_id)\n\u001B[32m   1219\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._threads_suspended_single_notification.notify_thread_suspended(thread_id, stop_reason):\n\u001B[32m-> \u001B[39m\u001B[32m1220\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Program Files\\JetBrains\\PyCharm 2022.3.3\\plugins\\python-ce\\helpers\\pydev\\pydevd.py:1235\u001B[39m, in \u001B[36mPyDB._do_wait_suspend\u001B[39m\u001B[34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[39m\n\u001B[32m   1232\u001B[39m             \u001B[38;5;28mself\u001B[39m._call_mpl_hook()\n\u001B[32m   1234\u001B[39m         \u001B[38;5;28mself\u001B[39m.process_internal_commands()\n\u001B[32m-> \u001B[39m\u001B[32m1235\u001B[39m         \u001B[43mtime\u001B[49m\u001B[43m.\u001B[49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   1237\u001B[39m \u001B[38;5;28mself\u001B[39m.cancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[32m   1239\u001B[39m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 61,
   "source": [
    "import enum\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "\n",
    "\n",
    "################################ eval notebook start ###################################\n",
    "class ObsBuffer(enum.Enum):\n",
    "    LABELS = \"labels\"\n",
    "    DEPTH = \"depth\"\n",
    "    AUTOMAP = \"automap\"\n",
    "\n",
    "\n",
    "DTYPE = torch.float32\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Seed random number generators\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if os.path.exists(\"seed.rnd\"):\n",
    "    with open(\"seed.rnd\", \"r\") as f:\n",
    "        seed = int(f.readline().strip())\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "else:\n",
    "    seed = 1337\n",
    "\n",
    "\n",
    "def make_env(seed, config) -> VizdoomMPEnv:\n",
    "    extra_state = None\n",
    "    if config[\"extra_state\"] is not None:\n",
    "        extra_state = []\n",
    "        for c in config[\"extra_state\"]:\n",
    "            if c in {e.value for e in ObsBuffer}:\n",
    "                extra_state.append(ObsBuffer(c))\n",
    "\n",
    "    env = VizdoomMPEnv(\n",
    "        num_players=1,\n",
    "        num_bots=4,\n",
    "        bot_skill=0,\n",
    "        doom_map=\"ROOM\",\n",
    "        episode_timeout=2000,\n",
    "        screen_format=config[\"screen_format\"],\n",
    "        n_stack_frames=config[\"n_stack_frames\"],\n",
    "        extra_state=extra_state,\n",
    "        hud=config[\"hud\"],\n",
    "        crosshair=config[\"crosshair\"],\n",
    "        seed=seed,\n",
    "    )\n",
    "    return env\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, model, config, device):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "\n",
    "    def select_action(self, frames):\n",
    "        frames = frames.unsqueeze(0).to(DEVICE, dtype=DTYPE)\n",
    "        logits = self.model(frames)\n",
    "        if isinstance(logits, tuple):\n",
    "            logits, _ = logits\n",
    "        if \"algo_type\" not in self.config or self.config[\"algo_type\"] == \"POLICY\":\n",
    "            act = Categorical(logits=logits).sample()\n",
    "        else:\n",
    "            act = logits.argmax(-1)\n",
    "        return act.cpu().numpy()[0]\n",
    "\n",
    "\n",
    "def run_episode(agent: Agent, seed: int = 1337):\n",
    "    env = make_env(seed, config=agent.config)\n",
    "    obs = env.reset()\n",
    "    score = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        obs = obs[0]\n",
    "        with torch.no_grad():\n",
    "            action = agent.select_action(obs)\n",
    "        obs, rwd, done, _ = env.step(action)\n",
    "        score += rwd[0]\n",
    "    env.close()\n",
    "    return score\n",
    "\n",
    "\n",
    "# Run evaluation\n",
    "config = PLAYER_CONFIG\n",
    "#config[\"extra_state\"] = \"depth\"\n",
    "n_episodes = 10\n",
    "model = restored_model\n",
    "model.eval()\n",
    "model = model.to(DEVICE, dtype=DTYPE)\n",
    "agent = Agent(model, config, DEVICE)\n",
    "\n",
    "# Evaluate model\n",
    "scores = []\n",
    "for i in range(n_episodes):\n",
    "    if seed is not None:\n",
    "        seed = np.random.randint(1e7)\n",
    "    scores.append(run_episode(agent, seed=seed))\n",
    "\n",
    "# Print result\n",
    "print(\"\\n\\n\\n\")\n",
    "print(np.mean(scores))"
   ],
   "id": "d5dac70c7f36c11e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
